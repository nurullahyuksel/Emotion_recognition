# -*- coding: utf-8 -*-
"""facial_expression_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eY6X0YWEOyXkL0c6M5qHuqe4NBrxb5RK
"""

# Commented out IPython magic to ensure Python compatibility.
# connect to colab

from google.colab import drive 
drive.mount('/content/drive')
# %cd drive/
!ls

import os 
os.chdir("/content/drive/My Drive/CNN/duygu_tanima")
!pwd

"""## Installing related packages

Uploading the necessary modules for data preparation, visualization and training to the notebook
"""

#import

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow.keras
from  tensorflow.keras.optimizers import  Adam
from  tensorflow.keras.models import Sequential, Model, model_from_json
from  tensorflow.keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization
from  tensorflow.keras.utils import load_img, img_to_array, array_to_img, to_categorical
from  tensorflow.keras.preprocessing import image_dataset_from_directory
from  tensorflow.keras.callbacks import ModelCheckpoint

"""# Loading the dataset"""

# Reading dataset with pandas and import to notebook
data= pd.read_csv("/content/drive/My Drive/CNN/duygu_tanima/data/fer2013.csv") 

# checking data size
data.shape

"""**Visualizing and examining the dataset**"""

# shows all columns and first 5 rows of dataset
data.head()

# The dataset is divided into three as Training, PuplicTest and PrivateTest. Let's count them..

data["Usage"].value_counts()

"""## Train Data preprocessing"""

# Let's take the data separated as "training" in the dataset. We will carry out our training process on this data.

np.unique(data["Usage"].values.ravel())  # --np.ravel-- Return a contiguous flattened array.

train_data= data[data.Usage=="Training"]  # let's assign the training examples to another variable

train_data.shape  # let's check the number of training data

# In the fer2013 dataset, the pixel values in the "pixels" column were created with spaces between them. let's arrange

train_pixels= train_data.pixels.str.split(" ").tolist() # We remove the spaces and add the pixel values to the list.

train_pixels= pd.DataFrame(train_pixels, dtype= int) # let's convert the pixel list to dataframe

train_images = train_pixels.values #Let's assign the pixel values to a new variable

train_images = train_images.astype(np.float)  #Let's change the type of the variable

print(train_images)  #let's see the variable

print(train_images.shape)  #let's see the variable size

"""### Visualizing"""

#edit figure size
plt.figure(figsize=(14,7))  

# Let's transform the pixel values into a 48x48 image and visualize it. 
#i used for loop to visualize top 10 data from dataset

for i in range (10):
  plt.subplot(2,5,1+i)
  plt.imshow(train_images[10+i].reshape(48,48), cmap="gray")

"""### Train emotion labels"""

#Let's determine how many classes are in the training set. namely different emotion labeled

train_labels_flat= train_data["emotion"].values.ravel()  #--np.ravel-- Return a contiguous flattened array.
train_labels_count= np.unique(train_labels_flat).shape[0] # how many unique labels are there
print("number of label :",train_labels_count )

# Let's determine the class of the data in the training set with onehot.
# Let the emotion of the data be 1 and the remaining emotions be 0.

def dense_to_one_hot (labels_dense, num_classes):
  num_labels= labels_dense.shape[0]
  index_offset = np.arange(num_labels)*num_classes
  labels_one_hot= np.zeros((num_labels, num_classes))
  labels_one_hot.flat[index_offset + labels_dense.ravel()]=1
  return labels_one_hot

# Let's determine the class values of the training data
y_train = dense_to_one_hot(train_labels_flat, train_labels_count)

y_train = y_train.astype(np.uint8)

print(y_train.shape)
print(y_train[15])

"""## Test Data preprocessing

we will use "PuplicTest" data to test the deep learning model
"""

# Let's take the data separated as "PuplicTest" in the dataset. We will carry out our test process on this data.

np.unique(data["Usage"].values.ravel())  # --np.ravel-- Return a contiguous flattened array.

test_data= data[data.Usage=="PublicTest"]  # let's assign the test examples to another variable

test_data.shape  # let's check the number of test data

# In the fer2013 dataset, the pixel values in the "pixels" column were created with spaces between them. let's arrange

test_pixels= test_data.pixels.str.split(" ").tolist() # We remove the spaces and add the pixel values to the list.

test_pixels= pd.DataFrame(test_pixels, dtype= int) # let's convert the pixel list to dataframe

test_images = test_pixels.values #Let's assign the pixel values to a new variable

test_images = test_images.astype(np.float)  #Let's change the type of the variable

print(test_images.shape)  #let's see the variable size

"""### Visualizing"""

#edit figure size
plt.figure(figsize=(14,7))  

# Let's transform the pixel values into a 48x48 image and visualize it. 
#i used for loop to visualize top 10 data from dataset

for i in range (10):
  plt.subplot(2,5,1+i)
  plt.imshow(test_images[i].reshape(48,48), cmap="gray")

"""### Test emotion labels"""

#Let's determine how many classes are in the training set. namely different emotion labeled

test_labels_flat= test_data["emotion"].values.ravel()  #--np.ravel-- Return a contiguous flattened array.
test_labels_count= np.unique(test_labels_flat).shape[0] # how many unique labels are there
print("number of label :",test_labels_count )

# Let's determine the class values of the training data
y_test = dense_to_one_hot(test_labels_flat, test_labels_count)

y_test = y_test.astype(np.uint8)

print(y_test.shape)
print(y_test[15])

"""# Creating a deep convolutional neural network model"""

from tensorflow.python.keras import activations
model= Sequential()  #Create an empty neural network model and assign it to variable "model"

# first layer

# "channels_last" corresponds to inputs with shape (batch_size, height, width, channels) 
# "input_shape: (height, width, channels)"
model.add(Conv2D(64,3, data_format="channels_last", kernel_initializer = "he_normal", input_shape= (48, 48, 1))) # filters: 64, kernel_size :3
model.add(BatchNormalization()) #Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.
model.add(Activation("relu"))


# Second layer

model.add(Conv2D(64,3))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPool2D(pool_size=(2,2), strides=2)) #Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input.
model.add(Dropout(0.6)) #The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.


# Third layer

model.add(Conv2D(32,3))
model.add(BatchNormalization())
model.add(Activation("relu"))


# Fourth layer

model.add(Conv2D(32,3))
model.add(BatchNormalization())
model.add(Activation("relu"))


# fifth layer

model.add(Conv2D(32,3))
model.add(BatchNormalization())
model.add(Activation("relu"))
model.add(MaxPool2D(pool_size=(2,2), strides=2)) 
model.add(Dropout(0.6))


# Full connected layers
model.add(Flatten()) #Flattens the input. Does not affect the batch size.
model.add(Flatten())
model.add(Dense(128))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.6))


# output layer
model.add(Dense(train_labels_count))
model.add(Activation("softmax"))
model.summary()

#compile

optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999) # let's use  "Adam" optimizer and edit optimization parameters

model.compile(loss="categorical_crossentropy", optimizer= optimizer, metrics=["accuracy"]) #loss function: "categorical_crossentropy",

# Let's bring the training and test datasets into a format suitable for training and prediction operations

x_train= train_images.reshape(train_images.shape[0],48,48,1)
x_test= test_images.reshape(test_images.shape[0],48,48,1)

print("x_train shape :", x_train.shape)
print("y_train shape :", y_train.shape) # number of classes
print("x_test shape :", x_test.shape)
print("y_test shape :", y_test.shape) # number of classes

"""# Traning"""

# save most successful weights ("accuracy")

checkpointer = ModelCheckpoint(filepath = "/content/drive/My Drive/CNN/duygu_tanima/data/face_model.h5", verbose=1, save_best_only=True) 
callbacks_list = [checkpointer]

# hyperparameters
epochs= 20
batch_size= 150

# run the model

hist = model.fit(x_train, y_train,
                 epochs=epochs,
                 shuffle=True,
                 batch_size=batch_size,
                 validation_data=(x_test, y_test),
                 callbacks= callbacks_list,
                 verbose=1)

# save model to json
model_json = model.to_json()
with open('/content/drive/My Drive/CNN/duygu_tanima/data/face_model.json', 'w') as json_file:
  json_file.write(model_json)

#visualize

plt.figure(figsize=(7,4))

plt.plot(hist.history["accuracy"], label= "train acc", color="g")
plt.plot(hist.history["val_accuracy"], label= "validation acc",color="r")
plt.legend()
plt.title("Model Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.savefig('face_recognition_accuracy.png')
plt.show()

plt.figure(figsize=(7,4))
plt.plot(hist.history["loss"], label= "train loss",color="g")
plt.plot(hist.history["val_loss"], label= "validation loss",color="r")
plt.legend()
plt.title("Model Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss(Cost)")
plt.savefig('face_recognition_loss.png')
plt.show()


plt.show()

#Saving
model_test=model.save("/content/drive/My Drive/CNN/duygu_tanima/data/face_model.h5")

"""# PrivateTest"""

# We will evaluate model performance for privatetest data

test= data[["emotion","pixels"]][data["Usage"]== "PrivateTest"] #Let's specify the PrivateTest data
test["pixels"] = test["pixels"].apply(lambda im: np.fromstring (im, sep= " ")) # --numpy.fromstring- A new 1-D array initialized from text data in a string.
test.head()

x_test_private = np.vstack(test["pixels"].values) # Stack arrays in sequence vertically (row wise).
y_test_private = np.array(test["emotion"]) # convert "emotion" data to array

# Let's convert the arrays to appropriate sizes

x_test_private = x_test_private.reshape(-1, 48,48,1) 
y_test_private = to_categorical(y_test_private) 

print("x_test_private shape :", x_test_private.shape)
print("y_test_private shape :", y_test_private.shape)

score = model.evaluate(x_test_private,y_test_private, verbose=0) # evaluating dataset

print(" PrivateTest loss: ", score[0]) # PrivateTest Loss
print(" PrivateTest Accuracy: ","%", score[1]*100, ) # PrivateTest Accuracy

"""# Real World Samples"""

#let's load the modules to load and size the images

from tensorflow.keras.models import load_model
from PIL import Image
from tensorflow.keras.preprocessing import image

# we recorded the best weights obtained in the training process. 
# We will use these weights

model_best= load_model("/content/drive/My Drive/CNN/duygu_tanima/data/face_model.h5")

# let's upload face photo for emotion recognition


real_image_path= "/content/drive/My Drive/CNN/duygu_tanima/images/emotion1.jpg" #file location of image

original_image= image.load_img(real_image_path) #original image

real_image= image.load_img(real_image_path, target_size= (48,48), grayscale=True) # upload photo and convert to grayscale

real_data= image.img_to_array(real_image) # convert image to array

real_data= np.expand_dims(real_data, axis=0)  # -- np.expand_dims--Insert a new axis that will appear at the axis position in the expanded array shape.
real_data= np.vstack([real_data]) # # Stack arrays in sequence vertically (row wise).

results= model_best.predict(real_data, batch_size) #predict the image, add predictions to "results" list

plt.imshow(original_image) #Let's show you the original photo
plt.title("Original image") 
plt.axis("off")
plt.show()

# Visualize

class_name=["Angry", "Disgust", "Fear", "Happy", "Sad", "Surprised", "Natural"] # emotion class names

emotion= class_name[np.argmax(results)] # highest rate emotion

plt.figure(figsize=(14,8)) # Figure size
plt.plot(class_name, results[0], label= emotion, linewidth=5, markersize=12) # draw the graph
plt.legend(fontsize=14)
plt.xlabel("Emotions", fontsize=20) # x axis name
plt.ylabel("classification score", fontsize=20) # y axis name
plt.xticks(rotation= 45, fontsize= 14)
plt.yticks(fontsize= 14)
plt.show()





